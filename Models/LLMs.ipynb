{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3f2b5bd",
   "metadata": {},
   "source": [
    "# LLMs \n",
    "### These are the foundational, general-purpose models. They are trained on vast amounts of text data to understand and generate human-like text for a wide variety of tasks like summarization, translation, and question-answering.Think of them as a massive, versatile library of language knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8fde4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "A large language model is a type of artificial intelligence model that is trained on a large amount of text data, typically in the form of written language. These models use deep learning techniques to learn the patterns and structure of natural language, allowing them to generate human-like text and perform tasks such as language translation and text summarization. Large language models are often used for natural language processing tasks and have gained popularity in recent years due to advancements in deep learning technology and the availability of large datasets. Examples of large language models include Google's BERT and OpenAI's GPT-3.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = OpenAI(model='gpt-3.5-turbo-instruct')\n",
    "\n",
    "result = llm.invoke(\"What is Large language model?\")\n",
    "\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
